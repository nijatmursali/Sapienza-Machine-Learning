{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import os \n",
    "\n",
    "#keras library \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "from klepto.archives import file_archive\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print(\"Tensorflow version %s\" %tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading DB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = file_archive(\"DBf/weatherData.txt\")\n",
    "db.load();\n",
    "perval=0.10;\n",
    "datadicdb=db['datadic']   \n",
    "l_datadicdb=db['l_datadic'] \n",
    "del db;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images    =[]\n",
    "train_labels    =[]\n",
    "test_images     =[]\n",
    "test_labels     =[]\n",
    "for ls_datadicdb in l_datadicdb:\n",
    "    lencd=len(datadicdb[ls_datadicdb])\n",
    "    cutld=int(lencd*(1-perval))\n",
    "    train_images+=( datadicdb[ls_datadicdb][:cutld])\n",
    "    train_labels+=( l_datadicdb[ls_datadicdb][:cutld])\n",
    "    test_images +=(datadicdb[ls_datadicdb][cutld+1:lencd])\n",
    "    test_labels +=( l_datadicdb[ls_datadicdb][cutld+1:lencd])\n",
    "\n",
    "train_images=np.array(train_images)\n",
    "train_labels=np.array(train_labels)-1\n",
    "test_images=np.array(test_images)\n",
    "test_labels=np.array(test_labels)-1\n",
    "\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "\n",
    "train_images3 = train_images\n",
    "test_images3 = test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Conv2D(8, 3, input_shape=(150, 150, 3), use_bias=False),\n",
    "  MaxPooling2D(pool_size=2),\n",
    "  Flatten(),\n",
    "  Dense(4, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(SGD(lr=.002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# checkpoint\n",
    "filepath=\"Weather-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(\n",
    "  train_images3,\n",
    "  to_categorical(train_labels),\n",
    "  batch_size=20,\n",
    "  epochs=10,\n",
    "  callbacks=callbacks_list,\n",
    "  validation_data=(test_images3, to_categorical(test_labels)),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
